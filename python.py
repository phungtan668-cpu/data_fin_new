import streamlit as st
import pandas as pd
import numpy as np
import json
from google import genai
from google.genai.errors import APIError
from io import StringIO
import re

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App ƒê√°nh Gi√° Ph∆∞∆°ng √Ån Kinh Doanh (Capital Budgeting)",
    layout="wide"
)

st.title("·ª®ng d·ª•ng ƒê√°nh gi√° Ph∆∞∆°ng √°n Kinh doanh üìà")
st.markdown("S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu v√† t√≠nh to√°n ch·ªâ s·ªë hi·ªáu qu·∫£ d·ª± √°n.")

# Th√™m numpy ƒë·ªÉ t√≠nh to√°n t√†i ch√≠nh
# --- C·∫•u tr√∫c d·ªØ li·ªáu y√™u c·∫ßu t·ª´ AI (JSON Schema) ---
EXTRACTION_SCHEMA = {
    "type": "OBJECT",
    "properties": {
        "V·ªën ƒë·∫ßu t∆∞ (tri·ªáu)": {"type": "NUMBER", "description": "T·ªïng v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu c·ªßa d·ª± √°n (t·∫°i th·ªùi ƒëi·ªÉm 0), ƒë∆°n v·ªã tri·ªáu VND."},
        "V√≤ng ƒë·ªùi d·ª± √°n (nƒÉm)": {"type": "NUMBER", "description": "Th·ªùi gian ho·∫°t ƒë·ªông c·ªßa d·ª± √°n (s·ªë nƒÉm)."},
        "Doanh thu h√†ng nƒÉm (tri·ªáu)": {"type": "NUMBER", "description": "Doanh thu ho·∫°t ƒë·ªông h√†ng nƒÉm ∆∞·ªõc t√≠nh, ƒë∆°n v·ªã tri·ªáu VND. Gi·∫£ ƒë·ªãnh l√† con s·ªë trung b√¨nh h√†ng nƒÉm."},
        "Chi ph√≠ h√†ng nƒÉm (tri·ªáu)": {"type": "NUMBER", "description": "T·ªïng chi ph√≠ ho·∫°t ƒë·ªông h√†ng nƒÉm (ch∆∞a bao g·ªìm thu·∫ø, l√£i vay, kh·∫•u hao), ƒë∆°n v·ªã tri·ªáu VND. Gi·∫£ ƒë·ªãnh l√† con s·ªë trung b√¨nh h√†ng nƒÉm."},
        "WACC (%)": {"type": "NUMBER", "description": "T·ª∑ l·ªá chi·∫øt kh·∫•u WACC (Weighted Average Cost of Capital) c·ªßa d·ª± √°n, ƒë∆°n v·ªã ph·∫ßn trƒÉm (%)."},
        "Thu·∫ø (%)": {"type": "NUMBER", "description": "Thu·∫ø su·∫•t thu·∫ø thu nh·∫≠p doanh nghi·ªáp, ƒë∆°n v·ªã ph·∫ßn trƒÉm (%)."}
    },
    "required": [
        "V·ªën ƒë·∫ßu t∆∞ (tri·ªáu)", "V√≤ng ƒë·ªùi d·ª± √°n (nƒÉm)", 
        "Doanh thu h√†ng nƒÉm (tri·ªáu)", "Chi ph√≠ h√†ng nƒÉm (tri·ªáu)", 
        "WACC (%)", "Thu·∫ø (%)"
    ]
}

# --- H√†m g·ªçi API Gemini ƒë·ªÉ Tr√≠ch xu·∫•t D·ªØ li·ªáu C·∫•u tr√∫c ---
def extract_data_from_document(document_text, api_key):
    """S·ª≠ d·ª•ng Gemini ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh theo ƒë·ªãnh d·∫°ng JSON."""
    try:
        client = genai.Client(api_key=api_key)
        
        # System prompt h∆∞·ªõng d·∫´n AI ƒë√≥ng vai tr√≤ chuy√™n gia ph√¢n t√≠ch v√† tu√¢n th·ªß JSON
        system_prompt = f"""
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc b·∫£n t√≥m t·∫Øt ph∆∞∆°ng √°n kinh doanh do kh√°ch h√†ng cung c·∫•p v√† tr√≠ch xu·∫•t s√°u (6) th√¥ng tin t√†i ch√≠nh c·ªët l√µi sau: V·ªën ƒë·∫ßu t∆∞, V√≤ng ƒë·ªùi d·ª± √°n, Doanh thu h√†ng nƒÉm, Chi ph√≠ h√†ng nƒÉm, WACC, v√† Thu·∫ø su·∫•t.
        
        C·∫ßn l∆∞u √Ω:
        1. ƒê∆°n v·ªã ti·ªÅn t·ªá l√† tri·ªáu VND.
        2. Doanh thu v√† Chi ph√≠ l√† c√°c con s·ªë ·ªïn ƒë·ªãnh h√†ng nƒÉm (Average Annual Figures).
        3. WACC v√† Thu·∫ø su·∫•t ph·∫£i l√† gi√° tr·ªã ph·∫ßn trƒÉm (%).
        4. K·∫øt qu·∫£ TR·∫¢ V·ªÄ DUY NH·∫§T d∆∞·ªõi d·∫°ng JSON theo schema ƒë√£ ƒë·ªãnh nghƒ©a. TUY·ªÜT ƒê·ªêI KH√îNG TH√äM B·∫§T K·ª≤ VƒÇN B·∫¢N GI·∫¢I TH√çCH N√ÄO NGO√ÄI KH·ªêI JSON.
        """

        prompt = f"""
        D∆∞·ªõi ƒë√¢y l√† n·ªôi dung vƒÉn b·∫£n c·ªßa ph∆∞∆°ng √°n kinh doanh:
        ---
        {document_text}
        ---
        H√£y tr√≠ch xu·∫•t 6 th√¥ng tin t√†i ch√≠nh b·∫Øt bu·ªôc v√† tr·∫£ v·ªÅ d∆∞·ªõi ƒë·ªãnh d·∫°ng JSON.
        """

        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            system_instruction=system_prompt,
            config={
                "response_mime_type": "application/json",
                "response_schema": EXTRACTION_SCHEMA
            }
        )
        
        # Ki·ªÉm tra v√† tr·∫£ v·ªÅ JSON
        if response.text:
            return json.loads(response.text)
        return None

    except APIError as e:
        st.error(f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}")
        return None
    except json.JSONDecodeError:
        st.error("L·ªói gi·∫£i m√£ JSON: AI kh√¥ng tr·∫£ v·ªÅ ƒë√∫ng ƒë·ªãnh d·∫°ng JSON. Vui l√≤ng ki·ªÉm tra n·ªôi dung file.")
        return None
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh trong qu√° tr√¨nh tr√≠ch xu·∫•t d·ªØ li·ªáu: {e}")
        return None

# --- H√†m t√≠nh to√°n D√≤ng ti·ªÅn v√† c√°c Ch·ªâ s·ªë ---
@st.cache_data
def calculate_project_metrics(data):
    """X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn v√† t√≠nh to√°n c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP."""
    
    # 1. Tr√≠ch xu·∫•t th√¥ng s·ªë
    I0 = data.get('V·ªën ƒë·∫ßu t∆∞ (tri·ªáu)')
    N = int(data.get('V√≤ng ƒë·ªùi d·ª± √°n (nƒÉm)'))
    Revenue = data.get('Doanh thu h√†ng nƒÉm (tri·ªáu)')
    Cost = data.get('Chi ph√≠ h√†ng nƒÉm (tri·ªáu)')
    WACC = data.get('WACC (%)') / 100.0  # Chuy·ªÉn WACC sang s·ªë th·∫≠p ph√¢n
    Tax = data.get('Thu·∫ø (%)') / 100.0    # Chuy·ªÉn Thu·∫ø sang s·ªë th·∫≠p ph√¢n
    
    # Gi·∫£ ƒë·ªãnh: Kh√¥ng c√≥ kh·∫•u hao v√† Gi√° tr·ªã thanh l√Ω (Simplified OCF)
    
    # 2. T√≠nh to√°n D√≤ng ti·ªÅn ho·∫°t ƒë·ªông h√†ng nƒÉm (Annual OCF)
    # OCF = (Revenue - Cost) * (1 - Tax)
    Annual_OCF = (Revenue - Cost) * (1 - Tax)
    
    if Annual_OCF <= 0:
        raise ValueError("L·ª£i nhu·∫≠n sau thu·∫ø h√†ng nƒÉm kh√¥ng d∆∞∆°ng. D·ª± √°n kh√¥ng kh·∫£ thi.")

    # 3. X√¢y d·ª±ng B·∫£ng d√≤ng ti·ªÅn
    years = list(range(N + 1))
    cash_flows = [-I0] + [Annual_OCF] * N
    
    df_cf = pd.DataFrame({
        'NƒÉm': years,
        'D√≤ng ti·ªÅn (CF)': cash_flows,
        'H·ªá s·ªë chi·∫øt kh·∫•u': [1.0] + [1 / (1 + WACC)**t for t in range(1, N + 1)],
    })
    
    # D√≤ng ti·ªÅn chi·∫øt kh·∫•u
    df_cf['D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)'] = df_cf['D√≤ng ti·ªÅn (CF)'] * df_cf['H·ªá s·ªë chi·∫øt kh·∫•u']
    
    # D√≤ng ti·ªÅn t√≠ch l≈©y v√† D√≤ng ti·ªÅn chi·∫øt kh·∫•u t√≠ch l≈©y
    df_cf['CF T√≠ch l≈©y'] = df_cf['D√≤ng ti·ªÅn (CF)'].cumsum()
    df_cf['DCF T√≠ch l≈©y'] = df_cf['D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)'].cumsum()
    
    # 4. T√≠nh to√°n c√°c ch·ªâ s·ªë
    
    # 4a. NPV (Net Present Value)
    NPV = df_cf['D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)'].sum()
    
    # 4b. IRR (Internal Rate of Return) - S·ª≠ d·ª•ng numpy.irr
    # L∆∞u √Ω: IRR c√≥ th·ªÉ kh√¥ng t√≠nh ƒë∆∞·ª£c n·∫øu d√≤ng ti·ªÅn kh√¥ng c√≥ s·ª± thay ƒë·ªïi d·∫•u (t·ª´ √¢m sang d∆∞∆°ng)
    try:
        IRR = np.irr(cash_flows)
    except:
        IRR = np.nan # G√°n NaN n·∫øu numpy kh√¥ng th·ªÉ t√≠nh ƒë∆∞·ª£c IRR
        
    # 4c. PP (Payback Period - Th·ªùi gian ho√†n v·ªën kh√¥ng chi·∫øt kh·∫•u)
    # T√¨m nƒÉm ƒë·∫ßu ti√™n m√† CF T√≠ch l≈©y >= 0
    df_positive_cf = df_cf[df_cf['CF T√≠ch l≈©y'] >= 0]
    if not df_positive_cf.empty:
        payback_year_int = df_positive_cf.iloc[0]['NƒÉm']
        # T√≠nh chi·∫øt kh·∫•u ph·∫ßn l·∫ª (interpolation)
        if payback_year_int > 0:
            cf_before = df_cf.loc[payback_year_int - 1, 'CF T√≠ch l≈©y']
            cf_current = df_cf.loc[payback_year_int, 'D√≤ng ti·ªÅn (CF)']
            PP = (payback_year_int - 1) + (abs(df_cf.loc[0, 'D√≤ng ti·ªÅn (CF)']) - df_cf.loc[payback_year_int - 1, 'CF T√≠ch l≈©y']) / cf_current
        else: # Ho√†n v·ªën ngay trong nƒÉm ƒë·∫ßu ti√™n
            PP = (abs(df_cf.loc[0, 'D√≤ng ti·ªÅn (CF)']) / Annual_OCF)
    else:
        PP = N + 1 # Kh√¥ng ho√†n v·ªën trong v√≤ng ƒë·ªùi d·ª± √°n

    # 4d. DPP (Discounted Payback Period - Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u)
    # T√¨m nƒÉm ƒë·∫ßu ti√™n m√† DCF T√≠ch l≈©y >= 0
    df_positive_dcf = df_cf[df_cf['DCF T√≠ch l≈©y'] >= 0]
    if not df_positive_dcf.empty:
        dpp_year_int = df_positive_dcf.iloc[0]['NƒÉm']
        # T√≠nh chi·∫øt kh·∫•u ph·∫ßn l·∫ª (interpolation)
        if dpp_year_int > 0:
            dcf_before = df_cf.loc[dpp_year_int - 1, 'DCF T√≠ch l≈©y']
            dcf_current = df_cf.loc[dpp_year_int, 'D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)']
            # L·∫•y CF g·ªëc I0 = abs(df_cf.loc[0, 'D√≤ng ti·ªÅn (CF)'])
            DPP = (dpp_year_int - 1) + (abs(df_cf.loc[0, 'D√≤ng ti·ªÅn (CF)']) - df_cf.loc[dpp_year_int - 1, 'DCF T√≠ch l≈©y']) / dcf_current
        else: # Ho√†n v·ªën ngay trong nƒÉm ƒë·∫ßu ti√™n
             # ƒêi·ªÅu n√†y r·∫•t kh√≥ x·∫£y ra, nh∆∞ng x·ª≠ l√Ω ƒë·ªÉ tr√°nh l·ªói
             DPP = (abs(df_cf.loc[0, 'D√≤ng ti·ªÅn (CF)']) / (Annual_OCF * df_cf.loc[1, 'H·ªá s·ªë chi·∫øt kh·∫•u']))
    else:
        DPP = N + 1 # Kh√¥ng ho√†n v·ªën trong v√≤ng ƒë·ªùi d·ª± √°n
        
    metrics = {
        'NPV': NPV,
        'IRR': IRR,
        'PP': PP,
        'DPP': DPP
    }
    
    return df_cf, metrics, data

# --- H√†m g·ªçi API Gemini ƒë·ªÉ Ph√¢n t√≠ch Ch·ªâ s·ªë ---
def get_ai_analysis_metrics(data, metrics, api_key):
    """G·ª≠i c√°c ch·ªâ s·ªë ƒë√£ t√≠nh to√°n ƒë·∫øn Gemini AI ƒë·ªÉ nh·∫≠n ph√¢n t√≠ch."""
    try:
        client = genai.Client(api_key=api_key)
        
        # Format l·∫°i d·ªØ li·ªáu cho prompt
        formatted_metrics = (
            f"V·ªën ƒë·∫ßu t∆∞: {data['V·ªën ƒë·∫ßu t∆∞ (tri·ªáu)']:,.0f} tri·ªáu VND, "
            f"V√≤ng ƒë·ªùi: {data['V√≤ng ƒë·ªùi d·ª± √°n (nƒÉm)']} nƒÉm, "
            f"WACC (T·ª∑ l·ªá chi·∫øt kh·∫•u): {data['WACC (%)']:.2f}%, "
            f"L·ª£i nhu·∫≠n sau thu·∫ø h√†ng nƒÉm (∆Ø·ªõc t√≠nh): {((data['Doanh thu h√†ng nƒÉm (tri·ªáu)'] - data['Chi ph√≠ h√†ng nƒÉm (tri·ªáu)']) * (1 - data['Thu·∫ø (%)']/100)):,.0f} tri·ªáu VND\n"
            f"--- Ch·ªâ s·ªë ƒë√°nh gi√° ---\n"
            f"NPV (Gi√° tr·ªã hi·ªán t·∫°i r√≤ng): {metrics['NPV']:,.0f} tri·ªáu VND\n"
            f"IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô): {metrics['IRR'] * 100:.2f}%\n"
            f"PP (Th·ªùi gian ho√†n v·ªën): {metrics['PP']:.2f} nƒÉm\n"
            f"DPP (Th·ªùi gian ho√†n v·ªën chi·∫øt kh·∫•u): {metrics['DPP']:.2f} nƒÉm"
        )
        
        # System prompt h∆∞·ªõng d·∫´n AI ƒë√≥ng vai tr√≤ chuy√™n gia ƒë√°nh gi√° d·ª± √°n
        system_prompt = "B·∫°n l√† m·ªôt chuy√™n gia th·∫©m ƒë·ªãnh d·ª± √°n ƒë·∫ßu t∆∞. H√£y ph√¢n t√≠ch kh√°ch quan v√† chuy√™n s√¢u v·ªÅ t√≠nh kh·∫£ thi c·ªßa d·ª± √°n d·ª±a tr√™n c√°c ch·ªâ s·ªë NPV, IRR, PP, v√† DPP. ƒê∆∞a ra k·∫øt lu·∫≠n (Accept/Reject) r√µ r√†ng. B√†i ph√¢n t√≠ch n√™n chia th√†nh 3 ƒëo·∫°n: 1. ƒê√°nh gi√° NPV & IRR so v·ªõi WACC. 2. Ph√¢n t√≠ch kh·∫£ nƒÉng thanh kho·∫£n (PP, DPP) v√† r·ªßi ro. 3. K·∫øt lu·∫≠n t·ªïng th·ªÉ."

        prompt = f"""
        Ph√¢n t√≠ch t√≠nh kh·∫£ thi c·ªßa d·ª± √°n kinh doanh v·ªõi c√°c th√¥ng s·ªë v√† ch·ªâ s·ªë ƒë√£ t√≠nh to√°n sau:
        
        {formatted_metrics}
        """

        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            system_instruction=system_prompt,
            tools=[{"google_search": {}}] # C√≥ th·ªÉ s·ª≠ d·ª•ng Google Search ƒë·ªÉ so s√°nh v·ªõi th·ªã tr∆∞·ªùng
        )
        
        return response.text

    except APIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --- Ch·ª©c nƒÉng 1: T·∫£i File v√† Tr√≠ch xu·∫•t D·ªØ li·ªáu ---

# T·∫£i file/N·ªôi dung
st.subheader("1. T·∫£i File ho·∫∑c D√°n N·ªôi dung Ph∆∞∆°ng √°n Kinh doanh")

uploaded_file = st.file_uploader(
    "T·∫£i l√™n file (.txt, .md, .docx). T·ªët nh·∫•t n√™n d√πng .txt ho·∫∑c .md ƒë·ªÉ AI d·ªÖ ƒë·ªçc n·ªôi dung.",
    type=['txt', 'md', 'docx']
)

# Area ƒë·ªÉ d√°n n·ªôi dung t·ª´ Word (gi·∫£i ph√°p thay th·∫ø cho th∆∞ vi·ªán docx)
document_text_area = st.text_area(
    "Ho·∫∑c d√°n to√†n b·ªô n·ªôi dung file Word v√†o ƒë√¢y:",
    height=200,
    key="document_text_input"
)

# X·ª≠ l√Ω n·ªôi dung ƒë·∫ßu v√†o
if uploaded_file is not None:
    try:
        if uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            st.warning("ƒê√£ ph√°t hi·ªán file Word (.docx). V√¨ gi·ªõi h·∫°n th∆∞ vi·ªán, vui l√≤ng ƒê·∫¢M B·∫¢O n·ªôi dung file Word ƒë∆∞·ª£c d√°n v√†o √¥ b√™n d∆∞·ªõi ƒë·ªÉ AI c√≥ th·ªÉ ƒë·ªçc ch√≠nh x√°c.")
            # ƒê·ªçc n·ªôi dung file Word th√¥, nh∆∞ng v·∫´n ∆∞u ti√™n text_area
            # D√π sao, ta s·∫Ω c·ªë g·∫Øng ƒë·ªçc file text n·∫øu ƒë√≥ l√† file text
            file_contents = StringIO(uploaded_file.getvalue().decode("utf-8")).read()
            if not document_text_area:
                 document_text = file_contents
            else:
                 document_text = document_text_area # ∆Øu ti√™n n·ªôi dung d√°n
        else:
            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
            document_text = stringio.read()
    except UnicodeDecodeError:
        st.error("L·ªói: Kh√¥ng th·ªÉ gi·∫£i m√£ file. Vui l√≤ng ƒë·∫£m b·∫£o file l√† vƒÉn b·∫£n thu·∫ßn t√∫y (.txt, .md) ho·∫∑c d√°n n·ªôi dung v√†o √¥ b√™n d∆∞·ªõi.")
        document_text = ""
else:
    document_text = document_text_area

# N√∫t th·ª±c hi·ªán thao t√°c l·ªçc d·ªØ li·ªáu
if st.button("L·ªçc D·ªØ li·ªáu T√†i ch√≠nh b·∫±ng AI", type="primary", use_container_width=True) and document_text:
    
    api_key = st.secrets.get("GEMINI_API_KEY") 
    
    if not api_key:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API 'GEMINI_API_KEY'. Vui l√≤ng c·∫•u h√¨nh Kh√≥a trong Streamlit Secrets.")
    else:
        with st.spinner('ƒêang g·ª≠i n·ªôi dung v√† ch·ªù Gemini AI tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c...'):
            extracted_data = extract_data_from_document(document_text, api_key)
            
            if extracted_data:
                st.session_state['extracted_data'] = extracted_data
                st.success("Tr√≠ch xu·∫•t d·ªØ li·ªáu th√†nh c√¥ng!")
            else:
                st.error("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i n·ªôi dung file.")

# --- Hi·ªÉn th·ªã v√† T√≠nh to√°n sau khi tr√≠ch xu·∫•t ---

if 'extracted_data' in st.session_state:
    data = st.session_state['extracted_data']
    
    try:
        # T√≠nh to√°n c√°c ch·ªâ s·ªë
        df_cf, metrics, clean_data = calculate_project_metrics(data)

        st.divider()

        # Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë√£ tr√≠ch xu·∫•t
        st.subheader("2. D·ªØ li·ªáu T√†i ch√≠nh ƒë√£ L·ªçc")
        col_list = list(clean_data.items())
        
        # Hi·ªÉn th·ªã trong 3 c·ªôt
        cols = st.columns(3)
        for i, (key, value) in enumerate(col_list):
            cols[i % 3].metric(
                label=key,
                value=f"{value:,.2f}" if isinstance(value, (int, float)) else str(value),
                help="ƒê∆°n v·ªã ti·ªÅn t·ªá l√† Tri·ªáu VND, WACC v√† Thu·∫ø l√† %"
            )

        st.divider()

        # Hi·ªÉn th·ªã B·∫£ng D√≤ng ti·ªÅn
        st.subheader("3. B·∫£ng D√≤ng ti·ªÅn D·ª± √°n (Cash Flow Table)")
        
        # ƒê·ªãnh d·∫°ng c·ªôt ti·ªÅn t·ªá
        st.dataframe(df_cf.style.format({
            'D√≤ng ti·ªÅn (CF)': '{:,.0f}',
            'H·ªá s·ªë chi·∫øt kh·∫•u': '{:.4f}',
            'D√≤ng ti·ªÅn chi·∫øt kh·∫•u (DCF)': '{:,.0f}',
            'CF T√≠ch l≈©y': '{:,.0f}',
            'DCF T√≠ch l≈©y': '{:,.0f}',
        }), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # Hi·ªÉn th·ªã c√°c ch·ªâ s·ªë ƒë√°nh gi√°
        st.subheader("4. C√°c Ch·ªâ s·ªë ƒê√°nh gi√° Hi·ªáu qu·∫£ D·ª± √°n")
        
        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
        
        with col_m1:
            st.metric("NPV (Gi√° tr·ªã hi·ªán t·∫°i r√≤ng)", f"{metrics['NPV']:,.0f} Tri·ªáu VND")
        
        with col_m2:
            st.metric("IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô)", f"{metrics['IRR'] * 100:.2f}%")
        
        with col_m3:
            st.metric("PP (Th·ªùi gian ho√†n v·ªën)", f"{metrics['PP']:.2f} NƒÉm")
        
        with col_m4:
            st.metric("DPP (Th·ªùi gian ho√†n v·ªën Cƒê)", f"{metrics['DPP']:.2f} NƒÉm")
            
        st.divider()

        # Ch·ª©c nƒÉng Y√™u c·∫ßu AI Ph√¢n t√≠ch
        st.subheader("5. Ph√¢n t√≠ch Hi·ªáu qu·∫£ D·ª± √°n (AI)")
        
        if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch Ch·ªâ s·ªë", use_container_width=True):
            api_key = st.secrets.get("GEMINI_API_KEY") 
            if api_key:
                with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                    ai_result = get_ai_analysis_metrics(clean_data, metrics, api_key)
                    st.markdown("---")
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    st.info(ai_result)
            else:
                 st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")

    except ValueError as ve:
        st.error(f"L·ªói t√≠nh to√°n: {ve}")
    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh t√≠nh to√°n: {e}")

else:
    st.info("Vui l√≤ng t·∫£i l√™n ho·∫∑c d√°n n·ªôi dung file v√† nh·∫•n n√∫t 'L·ªçc D·ªØ li·ªáu T√†i ch√≠nh b·∫±ng AI' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
